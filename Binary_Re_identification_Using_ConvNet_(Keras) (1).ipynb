{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Binary Re-identification Using ConvNet (Keras).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ix2eyZWzCWa",
        "colab_type": "code",
        "outputId": "8173a9b6-ddfc-4a4f-d728-741e62f00628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beQv5Y8t_3M4",
        "colab_type": "code",
        "outputId": "ee4fb28e-55b9-41aa-b7d0-1d7cd7dd6cfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "gdrive\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iq__R9VeNKSr",
        "colab_type": "text"
      },
      "source": [
        "##Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1wSgNCAu32u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify the input shape to the first convolutional layer\n",
        "\n",
        "input_shape = (120, 160, 3)\n",
        "nClasses = 2\n",
        "def createModel():\n",
        "    model = Sequential()\n",
        "    # a convolution layer of 32 features of size 3x3 with relu activation and zero padding\n",
        "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
        "    # a convolution layer of 32 features of size 3x3 with relu activation\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "    # a batch normalization layer\n",
        "    model.add(BatchNormalization())\n",
        "    # maxpooling layer of filter size 2x2\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    \n",
        "    # a convolution layer of 64 features of size 3x3 with relu activation and zero padding\n",
        "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "    # a convolution layer of 64 features of size 3x3 with relu activation\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    # a batch normalization layer\n",
        "    model.add(BatchNormalization())\n",
        "    # maxpooling layer of filter size 2x2\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    \n",
        "    # a convolution layer of 64 features of size 3x3 with relu activation and zero padding\n",
        "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "    # a convolution layer of 64 features of size 3x3 with relu activation\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    # a batch normalization layer\n",
        "    model.add(BatchNormalization())\n",
        "    # maxpooling layer of filter size 2x2\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    # a dropout layer of 50%\n",
        "    model.add(Dropout(0.5))\n",
        "    \n",
        "    # flatten the output of the previous layer\n",
        "    model.add(Flatten())\n",
        "    # add a dense layer that outputs 512 units and apply relu activation\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    # a dropout layer of 50%\n",
        "    model.add(Dropout(0.5))\n",
        "    # add a dense layer with a softmax activation to classify the images\n",
        "    model.add(Dense(nClasses, activation='softmax'))\n",
        "     \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrDRxMFcN3Gw",
        "colab_type": "text"
      },
      "source": [
        "##Load the old weights file and the save new best weights to the same file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5w9e3Bqu7y1",
        "colab_type": "code",
        "outputId": "c9e21f9f-aedf-41b2-b4ae-e39c3c38ee2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "model1 = createModel()\n",
        "model1.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model1.load_weights('gdrive/My Drive/ML/my_weights.hdf5')\n",
        "checkpointer = ModelCheckpoint(filepath='gdrive/My Drive/ML/my_weights.hdf5',monitor='val_acc', verbose=1, save_best_only=True) # To Checkpoint weights"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0gGQ_WMOFr8",
        "colab_type": "text"
      },
      "source": [
        "##Use ImageDataGenerator’s parameters to create a training validation split (0.2)\n",
        "We used data augmentation using the commented parameters and helped us to reach 95.69% validation accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2CCu1K7yBuF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen = ImageDataGenerator(\n",
        "    #featurewise_center=True,\n",
        "    #featurewise_std_normalization=True,\n",
        "    validation_split=0.2,\n",
        "    samplewise_center=True,\n",
        "    samplewise_std_normalization=True,\n",
        "#     horizontal_flip=True,\n",
        "#     zoom_range=0.1,\n",
        "#     rotation_range=10,\n",
        "#     width_shift_range=0.1,\n",
        "#     height_shift_range=0.1,\n",
        "#     shear_range=0.1,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCqYe8R3Ov7w",
        "colab_type": "text"
      },
      "source": [
        "##Use Keras’ ImageDataGenerator to read the modified dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4QsW-8X0bI3",
        "colab_type": "code",
        "outputId": "4796676a-0bc6-4a51-c174-5a645e7faff3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "batch_size=32\n",
        "train_generator = gen.flow_from_directory(\n",
        "    directory=\"gdrive/My Drive/ML/train\",\n",
        "    batch_size=batch_size,\n",
        "    target_size=(120, 160),\n",
        "    class_mode='binary',\n",
        "    seed=1,\n",
        "    subset=\"training\"\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3098 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etVxWC9eDRVE",
        "colab_type": "code",
        "outputId": "b3b91dbe-09f0-4a98-ada6-3e2c9a6eba00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "validation_generator = gen.flow_from_directory(\n",
        "        'gdrive/My Drive/ML/train',\n",
        "        batch_size=batch_size,\n",
        "        target_size=(120, 160),\n",
        "        class_mode='binary',\n",
        "        seed=1,\n",
        "        subset=\"validation\"\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 774 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MEAVWBMO0BU",
        "colab_type": "text"
      },
      "source": [
        "##Training\n",
        "\n",
        "####Choose the appropriate steps_per_epoch and validation_steps value. These values are related to the batch size. Justify your choice.\n",
        "\n",
        "For example, if the generator produces batches of size 32 samples and the whole training dataset is of size 2048 samples, then we need 64 batches of those to complete one epoch (Cover the whole train dataset) because 32*64 = 2048. That's why to know the number of steps per epoch (number of batches), we divide the total size of the dataset by the batch size. Same logic is applied for validation and test epochs. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkoWj_SvzLC6",
        "colab_type": "code",
        "outputId": "82085766-2671-4e1f-ab15-5ba79cfcd5f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "model1.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=train_generator.samples // batch_size,\n",
        "        epochs=2,\n",
        "        validation_data=validation_generator, \n",
        "        validation_steps=validation_generator.samples // batch_size,\n",
        "        callbacks=[checkpointer]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/2\n",
            "96/96 [==============================] - 778s 8s/step - loss: 0.0722 - acc: 0.9850 - val_loss: 0.4788 - val_acc: 0.9414\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.94141, saving model to gdrive/My Drive/ML/my_weights.hdf5\n",
            "Epoch 2/2\n",
            "96/96 [==============================] - 16s 168ms/step - loss: 0.0527 - acc: 0.9889 - val_loss: 0.3834 - val_acc: 0.9461\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.94141 to 0.94609, saving model to gdrive/My Drive/ML/my_weights.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f73c9e834e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nX39vHi4IZXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cell used to change the file of weights and apply it to test dataset.\n",
        "model1.load_weights('gdrive/My Drive/ML/my_weights.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kgQsBcsEahs",
        "colab_type": "text"
      },
      "source": [
        "#TESTING\n",
        "\n",
        "Testing Accuracy reaches 97.1%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9GwloI-8Xlp",
        "colab_type": "code",
        "outputId": "ccc8259e-f695-41f1-8190-852523dff1b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "test_datagen = ImageDataGenerator(\n",
        "       samplewise_center=True,\n",
        "       samplewise_std_normalization=True,\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        'gdrive/My Drive/ML/test',\n",
        "        target_size=(120, 160),\n",
        "        class_mode='binary',\n",
        "        batch_size=batch_size,\n",
        "        seed=1, \n",
        ")\n",
        "accuracy = model1.evaluate_generator(generator=test_generator, \n",
        "                                     steps=test_generator.samples/batch_size\n",
        "                                     )\n",
        "print(\"Accuracy =\", accuracy[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 860 images belonging to 2 classes.\n",
            "Accuracy = 0.963953488372093\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIOiCJFzu2rE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}